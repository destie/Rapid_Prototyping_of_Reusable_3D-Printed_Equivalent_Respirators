##############################################The following code takes 3D DICOM Scan data and saves the corresponding mesh###########################################
############################This is particularly useful in case one wants to load in brain scan data and see how an STL file would fit over it#######################


import pydicom as dicom
import os
import numpy as np
import scipy.ndimage
from skimage import measure, morphology
from mpl_toolkits.mplot3d.art3d import Poly3DCollection
import matplotlib.pyplot as plt
import cv2
import meshio



def loaddatainto3dmatric(path, threshold=-300):
#Load data into matrix
    slices = [dicom.read_file(path + '/' + s) for s in os.listdir(path)]
    slices.sort(key = lambda x: float(x.ImagePositionPatient[2]))
    try:
        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])
    except:
        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)
        
    for s in slices:
        s.SliceThickness = slice_thickness


    #Make image into stack 
    image = np.stack([s.pixel_array for s in slices])
    # Convert to int16 (from sometimes int16), 
    # should be possible as values should always be low enough (<32k)
    image = image.astype(np.int16)

    # Set outside-of-scan pixels to 0
    # The intercept is usually -1024, so air is approximately 0
    image[image == -2000] = 0
    
    # Convert to Hounsfield units (HU)
    for slice_number in range(len(slices)):
        
        intercept = slices[slice_number].RescaleIntercept
        slope = slices[slice_number].RescaleSlope
        
        if slope != 1:
            image[slice_number] = slope * image[slice_number].astype(np.float64)
            image[slice_number] = image[slice_number].astype(np.int16)
            
        image[slice_number] += np.int16(intercept)


    new_spacing=[1,1,1]

    # Determine current pixel spacing
    spacing = np.array([s.SliceThickness] + list(s.PixelSpacing), dtype=np.float32)

    resize_factor = np.round(image.shape*(spacing / new_spacing))/image.shape
    new_spacing = spacing / resize_factor
    
    image = scipy.ndimage.interpolation.zoom(image, resize_factor, mode='nearest')
    
    
    
    # Position the scan upright, 
    # so the head of the patient would be at the top facing the camera
    p = image.transpose(2,1,0)
    
    verts, faces,normals,values = measure.marching_cubes(p, threshold)


    fig = plt.figure(figsize=(10, 10))
    ax = fig.add_subplot(111, projection='3d')

    # Fancy indexing: `verts[faces]` to generate a collection of triangles
    mesh = Poly3DCollection(verts[faces], alpha=0.70)
    face_color = [0.45, 0.45, 0.75]
    mesh.set_facecolor(face_color)
    ax.add_collection3d(mesh)

    ax.set_xlim(0, p.shape[0])
    ax.set_ylim(0, p.shape[1])
    ax.set_zlim(0, p.shape[2])  
    #ax.view_init(90,270)
    ax.view_init(0,270)
    
    #Save the mesh as an STL object
    points = np.array(verts)
    cells = [("triangle", np.array(faces)]
    meshio.write_points_cells('out.vtu',points,cells)
